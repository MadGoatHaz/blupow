# HANDOVER-V2-CHECKPOINT :: DO NOT EDIT THIS FILE WITHOUT REVIEWING HANDOVER.md
"""Data update coordinator for the BluPow integration - Enhanced with comprehensive error handling."""
import asyncio
import logging
from typing import Any, Dict, Optional
from datetime import timedelta
from concurrent.futures import ThreadPoolExecutor
import functools
import subprocess
import json
import time
import traceback
import signal
from contextlib import asynccontextmanager

from homeassistant.core import HomeAssistant
from homeassistant.helpers.update_coordinator import DataUpdateCoordinator, UpdateFailed
from homeassistant.components import bluetooth

from .blupow_client import BluPowClient
from .const import DOMAIN

_LOGGER = logging.getLogger(__name__)

class CoordinatorHealthMonitor:
    """Monitor coordinator health and performance"""
    
    def __init__(self):
        self.update_attempts = 0
        self.successful_updates = 0
        self.failed_updates = 0
        self.consecutive_failures = 0
        self.last_success_time = None
        self.last_failure_time = None
        self.average_update_time = 0.0
        self.update_times = []
        self.error_patterns = {}
        self.system_issues = []
        self.process_failures = 0
        self.timeout_failures = 0
        
    def record_update_attempt(self, success: bool, duration: float = 0.0, error_type: str = None):
        """Record update attempt with detailed metrics"""
        self.update_attempts += 1
        
        if success:
            self.successful_updates += 1
            self.consecutive_failures = 0
            self.last_success_time = time.time()
            if duration > 0:
                self.update_times.append(duration)
                if len(self.update_times) > 30:  # Keep last 30 times
                    self.update_times.pop(0)
                self.average_update_time = sum(self.update_times) / len(self.update_times)
        else:
            self.failed_updates += 1
            self.consecutive_failures += 1
            self.last_failure_time = time.time()
            
            # Track error patterns
            if error_type:
                if error_type not in self.error_patterns:
                    self.error_patterns[error_type] = 0
                self.error_patterns[error_type] += 1
                
                # Track specific failure types
                if 'timeout' in error_type.lower():
                    self.timeout_failures += 1
                elif 'process' in error_type.lower():
                    self.process_failures += 1
    
    @property
    def success_rate(self) -> float:
        """Calculate success rate percentage"""
        if self.update_attempts == 0:
            return 0.0
        return (self.successful_updates / self.update_attempts) * 100
    
    @property
    def is_system_healthy(self) -> bool:
        """Determine if the system is healthy based on multiple factors"""
        if self.update_attempts < 3:
            return True  # Not enough data
            
        # Multiple health criteria
        criteria = [
            self.success_rate > 60.0,  # At least 60% success rate
            self.consecutive_failures < 8,  # Less than 8 consecutive failures
            self.process_failures < 5,  # Less than 5 process failures
            self.timeout_failures < 10  # Less than 10 timeout failures
        ]
        
        return sum(criteria) >= 3  # At least 3 out of 4 criteria met
    
    def get_diagnostics(self) -> Dict[str, Any]:
        """Get comprehensive diagnostic information"""
        return {
            'total_attempts': self.update_attempts,
            'success_rate': round(self.success_rate, 1),
            'consecutive_failures': self.consecutive_failures,
            'average_update_time': round(self.average_update_time, 2),
            'is_healthy': self.is_system_healthy,
            'last_success_age': time.time() - self.last_success_time if self.last_success_time else None,
            'error_patterns': self.error_patterns,
            'process_failures': self.process_failures,
            'timeout_failures': self.timeout_failures,
            'most_common_error': max(self.error_patterns.items(), key=lambda x: x[1]) if self.error_patterns else None
        }

class EnhancedSubprocessManager:
    """Manage subprocess execution with comprehensive error handling and monitoring"""
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
        self.active_processes = {}
        self.process_counter = 0
        
    @asynccontextmanager
    async def managed_subprocess(self, script: str, timeout: float = 30.0, operation_id: str = None):
        """Context manager for safe subprocess execution"""
        if operation_id is None:
            self.process_counter += 1
            operation_id = f"blupow_subprocess_{self.process_counter}"
            
        process = None
        start_time = time.time()
        
        try:
            self.logger.debug(f"🚀 Starting subprocess {operation_id} with timeout {timeout}s")
            
            # Create subprocess with enhanced monitoring
            process = await asyncio.create_subprocess_exec(
                'python3', '-c', script,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                preexec_fn=lambda: signal.signal(signal.SIGTERM, signal.SIG_DFL)
            )
            
            self.active_processes[operation_id] = {
                'process': process,
                'start_time': start_time,
                'timeout': timeout
            }
            
            # Wait for completion with timeout
            try:
                stdout, stderr = await asyncio.wait_for(process.communicate(), timeout=timeout)
                duration = time.time() - start_time
                
                output = stdout.decode().strip()
                stderr_output = stderr.decode().strip()
                
                # Log subprocess details
                self.logger.debug(f"✅ Subprocess {operation_id} completed in {duration:.2f}s")
                
                if stderr_output:
                    self.logger.debug(f"Subprocess stderr: {stderr_output}")
                
                yield {
                    'success': True,
                    'output': output,
                    'stderr': stderr_output,
                    'duration': duration,
                    'return_code': process.returncode
                }
                
            except asyncio.TimeoutError:
                self.logger.error(f"⏰ Subprocess {operation_id} timed out after {timeout}s")
                yield {
                    'success': False,
                    'error': f'Subprocess timeout after {timeout}s',
                    'duration': time.time() - start_time,
                    'error_type': 'timeout'
                }
                
        except Exception as e:
            duration = time.time() - start_time
            error_msg = f"Subprocess execution error: {str(e)}"
            self.logger.error(f"💥 {error_msg}")
            yield {
                'success': False,
                'error': error_msg,
                'duration': duration,
                'error_type': 'process_error'
            }
            
        finally:
            # Cleanup process
            if process and process.returncode is None:
                try:
                    self.logger.debug(f"🧹 Cleaning up subprocess {operation_id}")
                    process.terminate()
                    await asyncio.wait_for(process.wait(), timeout=5.0)
                except asyncio.TimeoutError:
                    self.logger.warning(f"Force killing subprocess {operation_id}")
                    process.kill()
                    await process.wait()
                except Exception as e:
                    self.logger.error(f"Error during subprocess cleanup: {e}")
            
            # Remove from active processes
            if operation_id in self.active_processes:
                del self.active_processes[operation_id]

class BluPowDataUpdateCoordinator(DataUpdateCoordinator[Dict[str, Any]]):
    """Enhanced data update coordinator with comprehensive monitoring and error handling."""

    def __init__(self, hass: HomeAssistant, mac_address: str) -> None:
        """Initialize the enhanced data update coordinator."""
        self.mac_address = mac_address
        self.client = BluPowClient(mac_address)
        self.ble_device = bluetooth.async_ble_device_from_address(
            hass, mac_address.upper(), connectable=True
        ) if mac_address else None
        
        # Enhanced monitoring and management
        self.health_monitor = CoordinatorHealthMonitor()
        self.subprocess_manager = EnhancedSubprocessManager(_LOGGER)
        
        # Legacy attributes maintained for compatibility
        self._executor = ThreadPoolExecutor(max_workers=1, thread_name_prefix="BluPow-BT")
        self._last_successful_data = {}
        self._consecutive_failures = 0
        self._last_success_time = None
        self._last_health_report = 0
        self._health_report_interval = 600  # Every 10 minutes

        super().__init__(
            hass,
            _LOGGER,
            name=DOMAIN,
            update_interval=timedelta(seconds=30),
            update_method=self._async_update_data,
        )
        _LOGGER.info("✨ Enhanced BluPow coordinator initialized for device: %s", mac_address)

    async def _async_update_data(self) -> Dict[str, Any]:
        """Enhanced data update with comprehensive error handling and monitoring."""
        operation_start = time.time()
        _LOGGER.debug(f"🔄 Starting enhanced data update for {self.mac_address}")
        
        try:
            # Log health report periodically
            await self._log_health_report_if_needed()
            
            # Calculate adaptive timeout based on health
            base_timeout = 25.0
            health_multiplier = 1.0
            
            if self.health_monitor.consecutive_failures > 3:
                health_multiplier = 1.5  # Increase timeout for unhealthy systems
            elif self.health_monitor.consecutive_failures > 6:
                health_multiplier = 2.0  # Even more time for very unhealthy systems
                
            timeout = min(base_timeout * health_multiplier, 60.0)  # Cap at 60s
            
            # Create enhanced isolation script with better error handling
            script = self._create_enhanced_isolation_script()
            
            # Execute with managed subprocess
            async with self.subprocess_manager.managed_subprocess(
                script, timeout=timeout, operation_id=f"data_update_{int(time.time())}"
            ) as result:
                
                duration = time.time() - operation_start
                
                if result['success'] and result['output'].startswith("SUCCESS:"):
                    # Parse successful data
                    data_str = result['output'][8:]  # Remove "SUCCESS:" prefix
                    data = eval(data_str)  # Safe since we control the format
                    
                    # Record success metrics
                    self.health_monitor.record_update_attempt(True, duration)
                    self._consecutive_failures = 0
                    self._last_success_time = time.time()
                    self._last_successful_data = data.copy()
                    
                    _LOGGER.info(f"✅ SUBPROCESS SUCCESS: Retrieved {len(data)} fields in {duration:.1f}s")
                    
                    # Enhanced logging with key values
                    key_values = {k: v for k, v in data.items() 
                                if k in ['model', 'input_voltage', 'battery_voltage', 'temperature'] 
                                and v is not None}
                    _LOGGER.info(f"🎯 REAL DATA: {key_values}")
                    
                    data['connection_status'] = 'connected'
                    data['last_update'] = time.time()
                    data['health_status'] = 'healthy' if self.health_monitor.is_system_healthy else 'degraded'
                    
                    return data
                    
                else:
                    # Handle failure with detailed error tracking
                    error_type = result.get('error_type', 'unknown_error')
                    error_msg = result.get('error', 'Unknown subprocess error')
                    
                    self.health_monitor.record_update_attempt(False, duration, error_type)
                    self._consecutive_failures += 1
                    
                    _LOGGER.error(f"❌ SUBPROCESS FAILED: {error_msg} (Duration: {duration:.1f}s)")
                    
                    # Return fallback data with error information
                    fallback_data = self._get_enhanced_fallback_data()
                    fallback_data.update({
                        'connection_status': 'error',
                        'last_error': error_msg,
                        'last_error_time': time.time(),
                        'consecutive_failures': self._consecutive_failures,
                        'health_status': 'unhealthy' if self._consecutive_failures > 5 else 'degraded'
                    })
                    
                    return fallback_data
                    
        except Exception as e:
            # Handle unexpected coordinator errors
            duration = time.time() - operation_start
            error_msg = f"Coordinator exception: {str(e)}"
            
            self.health_monitor.record_update_attempt(False, duration, 'coordinator_exception')
            self._consecutive_failures += 1
            
            _LOGGER.error(f"💥 COORDINATOR ERROR: {error_msg}")
            _LOGGER.debug(f"Traceback: {traceback.format_exc()}")
            
            # Return emergency fallback
            emergency_data = self._get_emergency_fallback_data()
            emergency_data.update({
                'connection_status': 'coordinator_error',
                'last_error': error_msg,
                'last_error_time': time.time(),
                'health_status': 'critical'
            })
            
            return emergency_data

    def _create_enhanced_isolation_script(self) -> str:
        """Create an enhanced isolation script with better error handling and monitoring"""
        return f'''
import asyncio
import sys
import logging
import signal
import time
import traceback
import json

# Configure logging to reduce noise but capture errors
logging.basicConfig(level=logging.WARNING, format='%(levelname)s: %(message)s')

# Add path for our custom component
sys.path.append("/config/custom_components")

# Global error tracking
script_errors = []

def timeout_handler(signum, frame):
    print("ERROR:Hard script timeout - process killed")
    sys.exit(1)

def log_error(error_msg):
    """Log error with timestamp"""
    script_errors.append({{"timestamp": time.time(), "error": str(error_msg)}})
    print(f"SCRIPT_ERROR:{{error_msg}}")

# Set up hard timeout protection
signal.signal(signal.SIGALRM, timeout_handler)
signal.alarm(50)  # Hard timeout at 50 seconds

async def enhanced_data_retrieval():
    """Enhanced data retrieval with comprehensive error handling"""
    client = None
    connection_attempts = 0
    max_attempts = 3
    
    try:
        from blupow.blupow_client import BluPowClient
        
        client = BluPowClient("{self.mac_address}")
        
        # Enhanced connection with multiple retry strategies
        for attempt in range(max_attempts):
            connection_attempts += 1
            
            try:
                if attempt > 0:
                    backoff_time = min(2.0 * attempt, 5.0)  # Exponential backoff, max 5s
                    print(f"RETRY:Attempt {{attempt + 1}}/{{max_attempts}} after {{backoff_time}}s delay")
                    await asyncio.sleep(backoff_time)
                
                connection_start = time.time()
                connected = await client.connect()
                connection_time = time.time() - connection_start
                
                if connected:
                    print(f"CONNECTION_SUCCESS:Connected in {{connection_time:.2f}}s")
                    break
                else:
                    error_msg = f"Connection failed on attempt {{attempt + 1}}"
                    log_error(error_msg)
                    if attempt == max_attempts - 1:
                        print(f"ERROR:All {{max_attempts}} connection attempts failed")
                        return False
                        
            except Exception as e:
                error_msg = f"Connection attempt {{attempt + 1}} exception: {{str(e)}}"
                log_error(error_msg)
                if attempt == max_attempts - 1:
                    print(f"ERROR:Connection exceptions on all attempts")
                    return False
        
        # Enhanced data reading with validation
        data_start = time.time()
        data = await client.read_device_info()
        data_time = time.time() - data_start
        
        # Comprehensive data validation
        if not data:
            log_error("No data returned from device")
            print("ERROR:No data retrieved from device")
            return False
            
        if not isinstance(data, dict):
            log_error(f"Invalid data type: {{type(data)}}")
            print("ERROR:Invalid data format returned")
            return False
            
        if len(data) == 0:
            log_error("Empty data dictionary returned")
            print("ERROR:Empty data dictionary")
            return False
        
        # Enhanced data processing and validation
        validated_data = {{}}
        required_fields = ['model', 'device_id']
        missing_required = []
        
        for key, value in data.items():
            if value is not None:
                # Convert complex types to JSON-serializable format
                if isinstance(value, (int, float, bool, str)):
                    validated_data[key] = value
                else:
                    validated_data[key] = str(value)
            else:
                validated_data[key] = None
                
        # Check for required fields
        for field in required_fields:
            if field not in validated_data or validated_data[field] is None:
                missing_required.append(field)
        
        if missing_required:
            log_error(f"Missing required fields: {{missing_required}}")
            print(f"WARNING:Missing required fields: {{missing_required}}")
        
        # Add metadata
        validated_data.update({{
            '_retrieval_time': data_time,
            '_connection_attempts': connection_attempts,
            '_script_errors': script_errors,
            '_validation_timestamp': time.time()
        }})
        
        print(f"DATA_VALIDATION:{{len(validated_data)}} fields validated in {{data_time:.2f}}s")
        print("SUCCESS:" + json.dumps(validated_data, default=str))
        return True
        
    except Exception as e:
        error_msg = f"Script execution exception: {{str(e)}}"
        log_error(error_msg)
        print(f"ERROR:{{error_msg}}")
        print(f"TRACEBACK:{{traceback.format_exc()}}")
        return False
        
    finally:
        # Enhanced cleanup with error handling
        if client:
            try:
                if hasattr(client, 'is_connected') and client.is_connected:
                    disconnect_start = time.time()
                    await client.disconnect()
                    disconnect_time = time.time() - disconnect_start
                    print(f"DISCONNECT:Completed in {{disconnect_time:.2f}}s")
            except Exception as e:
                log_error(f"Disconnect error: {{str(e)}}")
                print(f"WARNING:Disconnect error: {{str(e)}}")
        
        # Cancel timeout alarm
        signal.alarm(0)

# Execute with top-level exception handling
try:
    result = asyncio.run(enhanced_data_retrieval())
    if not result:
        sys.exit(1)
        
except KeyboardInterrupt:
    print("ERROR:Script interrupted")
    sys.exit(1)
    
except Exception as e:
    print(f"ERROR:Top-level script exception: {{str(e)}}")
    print(f"TRACEBACK:{{traceback.format_exc()}}")
    sys.exit(1)
'''

    def _get_enhanced_fallback_data(self) -> Dict[str, Any]:
        """Get enhanced fallback data with health information"""
        # Start with last successful data if recent
        if (self._last_successful_data and 
            self._last_success_time and 
            time.time() - self._last_success_time < 600):  # 10 minutes
            
            fallback_data = self._last_successful_data.copy() 
            fallback_data.update({
                'connection_status': 'offline_recent',
                'data_age': time.time() - self._last_success_time,
                'last_update': self._last_success_time
            })
            return fallback_data
        
        # Otherwise return basic offline structure
        return self.client.get_data()

    def _get_emergency_fallback_data(self) -> Dict[str, Any]:
        """Get emergency fallback data for critical coordinator errors"""
        return {
            'connection_status': 'emergency_fallback',
            'model': 'Unknown',
            'device_id': 'Unknown',
            'last_update': time.time(),
            'error_message': 'Coordinator experiencing critical errors'
        }

    async def _log_health_report_if_needed(self):
        """Log comprehensive health report periodically"""
        current_time = time.time()
        if current_time - self._last_health_report >= self._health_report_interval:
            
            diagnostics = self.health_monitor.get_diagnostics()
            
            if diagnostics['total_attempts'] > 0:
                status_emoji = "🟢" if diagnostics['is_healthy'] else "🟡" if diagnostics['success_rate'] > 30 else "🔴"
                
                _LOGGER.info(
                    f"📊 BluPow Coordinator Health Report [{status_emoji}]: "
                    f"Success Rate: {diagnostics['success_rate']}%, "
                    f"Consecutive Failures: {diagnostics['consecutive_failures']}, "
                    f"Avg Update Time: {diagnostics['average_update_time']}s"
                )
                
                # Log error patterns if any
                if diagnostics['error_patterns']:
                    _LOGGER.info(f"🔍 Error Patterns: {diagnostics['error_patterns']}")
                
                # Log most common error
                if diagnostics['most_common_error']:
                    error_type, count = diagnostics['most_common_error']
                    _LOGGER.warning(f"⚠️ Most Common Error: '{error_type}' ({count} occurrences)")
            
            self._last_health_report = current_time

    @property
    def device_info(self) -> Dict[str, Any]:
        """Return basic device information."""
        model = "Unknown"
        if self.data and self.data.get('model_number'):
            model = self.data.get('model_number')

        name = "BluPow Device"
        if self.ble_device and self.ble_device.name:
            name = self.ble_device.name

        return {
            "identifiers": {(DOMAIN, self.mac_address)},
            "name": name,
            "model": model,
            "manufacturer": "Renogy",
        }

    async def enable_test_mode(self) -> None:
        """Enable test mode with simulated data for debugging."""
        _LOGGER.info("Enabling test mode for BluPow coordinator")
        # Override get_data to return test data
        original_get_data = self.client.get_data
        self.client.get_data = self.client.get_test_data
        await self.async_refresh()

    async def async_shutdown(self):
        """Shutdown coordinator."""
        if hasattr(self, '_executor'):
            self._executor.shutdown(wait=True)
        if self.client and self.client.is_connected:
            await self.client.disconnect()

